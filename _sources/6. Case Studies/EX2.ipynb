{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The size of character parts from largest to smallest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates analysing spoken part size of characters from a set of Shakespear plays with the help of <ins>SIA API</ins>.\n",
    "\n",
    "_@Hugh, some explaination about the purpose of doing this experiment_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, a number of dependency modules are imported here.\n",
    "\n",
    "- `requests`: is used for sending requests to the SIA API.\n",
    "- `matplotlib.pyplot`: we use the Matplotlib to create the chart based on the results from the SIA API.\n",
    "- `IPython.display`: is used for rendering the results from the SIA API as HTML tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up the API endpoint here. In this example, we use the <ins>Word Frequencies API</ins>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_url = \"https://sia.ardc-hdcl-sia-iaw.cloud.edu.au/api/v1/word-frequencies\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the API, an API key is requried to authenticate the requests. The API key must be specified in a custom HTTP header `X-API-KEY` and sent along with every request.\n",
    "\n",
    "You should use your own API keys for your own notebooks and always keep your keys confidential. Read more about <ins>how to create API keys</ins> in SIA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_key = \"255446bcdde7ca9fe776258d09e8411bbb8d1cade2ebd6aba440f80f6817c3fd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we start to prepare the request data which we can send to the Word Frequencies API. In this example, we are going to use a text set containing 20 Shakespear plays which has been already uploaded in the SIA platform. Instead of passing the actual text contents to the API, we can tell the API to use one of the texts or text sets from SIA by specifying its ID.\n",
    "\n",
    "The URL of a text/text set page from <ins>SIA Application</ins> indicates the ID of that text/text set. For example:\n",
    "\n",
    "```\n",
    "https://sia.ardc-hdcl-sia-iaw.cloud.edu.au/text-sets/86\n",
    "```\n",
    "\n",
    "In this case, the ID of the \"20 Shakespear plays\" text set is `86`.\n",
    "\n",
    "We will also pass serveral word frequecies options to the Word Frequencies API. These options are:\n",
    "\n",
    "- `segmentByCharacter`: We will segment these plays by characters.\n",
    "- `blockMethod`: We set the block method to `0`(By text), which segments play characters in the scope of each text.\n",
    "- `excludeWords`: We are excluding some common punctuation marks from our analysis.\n",
    "\n",
    "To view more details about options of Word Frequencies API, read the <ins>API documentation</ins>.\n",
    "\n",
    "_@Hugh: more explainations about these options may be specified here_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_data = {\n",
    "    'textSet': 86,\n",
    "    'option': {\n",
    "        'segmentByCharacter': True,  #Segment by character\n",
    "        'blockMethod' : 0,           #Segment by text\n",
    "        'excludeWords': [\"[\",\"\\\\\", \"]\", \"_\", \"`\", \"!\", \"\\\"\", \"#\", \"%\", \"'\", \"(\", \")\", \"+\", \",\", \"-\", \"â€“\", \".\", \"/\", \":\", \";\", \"{\", \"|\", \"}\", \"=\", \"~\", \"?\" ],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SIA API accept JSON as the request data. Here we have constructed a Python dictionary object with the text set identifier and the word frequencies options. Next we are going to put all things together and use the [Requests](https://requests.readthedocs.io/en/latest/) module to send the request to the SIA API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make API request\n",
    "response = requests.post(request_url, json=request_data, headers={\"X-API-KEY\": api_key}, timeout=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have specified the API endpoint, request data we defined earlier and the `X-API-KEY` HTTP header for the API request and received the response. Please note that the API call can take serveral minutes to finish based on the size of the text or text set. Therefore, we have set the request timeout to `1200` seconds.\n",
    "\n",
    "Before we start unpacking the response data, we want to make sure the API call was successful by checking the HTTP response code. Read the <ins>API documentation</ins> for all error codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{response.status_code} {response.reason}\")\n",
    "assert response.status_code == 200\n",
    "response_data = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the response data ready from Word Frequencies API. We firstly want to list all characters from these plays in a table and sort them from the highest spoken part size to the lowest. We are going to unpack the response data and extract the information related to our experiment. Read more about the <ins>response data</ins> of Word Frequencies API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold word counts from all characters.\n",
    "character_word_counts = {}\n",
    "for block in response_data['blocks']:\n",
    "    character_word_counts[block['name']] = block['size']\n",
    "\n",
    "# Sort by word count.\n",
    "character_word_counts = dict(sorted(character_word_counts.items(), key=lambda item: item[1], reverse=True)) # Python 3.7+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created a dictionary which uses character names as keys and spoken part size as values. Then we sorted the dictionary by the spoken part size from highest to lowest (Note that sorting dictionary is only supported in Python 3.7+. If you are using order versions of Python, you might need to use `OrderedDict` instead).\n",
    "\n",
    "The next step is to generate the HTML markups based on the dictionary we created and render it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table dispaly\n",
    "html = '<div style=\"overflow: auto; max-height: 500px; margin-top: 40px;\"><table border=\"1\">'\n",
    "\n",
    "# Add table header\n",
    "html += '<tr><th>Rank</th><th>Character</th><th>Size</th></tr>'\n",
    "\n",
    "# Add table rows\n",
    "i = 0\n",
    "for character_name, word_count in character_word_counts.items():\n",
    "    i += 1\n",
    "    html += f\"<tr><td>{str(i)}</td><td>{character_name}</td><td>{str(word_count)}</td></tr>\"\n",
    "\n",
    "html += '</table></div>'\n",
    "\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have created a 3-column table. Each cell in the \"Character\" column contains the play name and the character name from that play separated by tilde (`~`).\n",
    "\n",
    "_@Hugh: more insights about the table can be described here_\n",
    "\n",
    "Next, we are going to visualise these data in a scatter plot using the [Matplotlib](https://matplotlib.org/) library. Note that the plot will only show the top 640 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the rank range from 1 to 640.\n",
    "ranks = range(1, 641)\n",
    "\n",
    "# Slice top 640 characters from the list. \n",
    "sizes = list(character_word_counts.values())[0:640]\n",
    "\n",
    "# Scatterplot\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.scatter(ranks, sizes, c='blue')\n",
    "plt.xticks(range(0, 701, 100))  # Set tick marks up to 700\n",
    "plt.xlim([0, 700])  # Set x-axis limits up to 700\n",
    "plt.ylim([0, 12000]) # Set x-axis limits up to 12000\n",
    "plt.xlabel('Rank')\n",
    "plt.ylabel('Size of Spoken Part')\n",
    "plt.title('Size of Character Parts in 20 Shakespeare Plays')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_@Hugh: some insights about the chart_"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
